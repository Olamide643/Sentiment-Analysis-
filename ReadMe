# Sentiment Analysis GRU Model Implementation

## Overview
This project implements a **Sentiment Analysis** model using a neural network architecture built with **Keras**. The model classifies text into binary sentiment categories (positive or negative) by leveraging word embeddings and **Gated Recurrent Units (GRU)** layers. The app provides a web interface for real-time sentiment analysis using **Flask**.

---

## Key Features

### Tokenizer Initialization
- **Tokenizer:** A `Tokenizer` object is initialized with a vocabulary size of **10,000** most frequent words.
- **Text Preprocessing:** The tokenizer is fitted on the input data (`X`) and converts the text into integer sequences using `fit_on_texts(X)`.

### Model Architecture
1. **Embedding Layer**
   - Transforms word indices into dense vectors with an embedding size of **20**.
   - Input dimension set to **20,000** to accommodate the vocabulary size.
   - Input sequence length is defined by `len_max`.

2. **GRU Layers**
   - The model includes three **GRU** layers with decreasing unit sizes:
     - **First GRU Layer:** 16 units, returns sequences.
     - **Second GRU Layer:** 8 units, returns sequences.
     - **Third GRU Layer:** 4 units, does not return sequences (final GRU layer).

3. **Dense Layer**
   - A fully connected **Dense** layer with **1 output neuron** and a sigmoid activation function for binary classification.

### Model Compilation
- **Loss Function:** `binary_crossentropy` for binary classification.
- **Optimizer:** Adam optimizer with a learning rate of **0.001**.
- **Metric:** Accuracy to evaluate model performance.

---

## Flask Web Application

### Home Route (`/`)
- Renders a basic HTML template (`Home.html`) where users can input text for classification.

### Prediction Route (`/predict`)
- Receives **POST** requests with user input from the form.
- The input text is tokenized, padded, and fed into the model for prediction.
- If the model's prediction is greater than **0.5**, the text is classified as **Positive**, otherwise **Negative**.
- The classification result and the prediction probability are displayed on the result page.

---

## Model Prediction Flow

### Tokenization & Padding
- The input text is tokenized and converted into integer sequences using the pre-trained tokenizer.
- **Padding** ensures that all sequences match the expected input length of **241 tokens**.

### Prediction Output
- The model outputs a value between **0 and 1**, representing the probability of the text being positive.
- A threshold of **0.5** is used to classify the input as either **Positive** or **Negative**, and the confidence percentage is displayed.

---

## How to Run the App

1. Clone the repository and install the necessary dependencies:
   ```bash
   git clone <repository-url>
   cd <project-directory>
   pip install -r requirements.txt
